{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size = 5> Searching for the most reliable model for the \"Absenteeism at work\" dataset. </font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size = 5> Table of content: </font> <br>\n",
    "- [Multiple linear regression model with TensorFlow](#Multiple_linear_regression_with_TensorFlow)\n",
    "- [Neural network regression model with Keras](#Neural_network_regression_with_Keras)\n",
    "- [K-Means Clustering](#K_Means_Clustering)\n",
    "- [Multilabel Classification with TensorFlow](#Multilabel_classification_with_TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Multiple_linear_regression_with_TensorFlow'></a>\n",
    "<center> <font size=5> I. Multiple linear regression model with TensorFlow </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason_for_absence</th>\n",
       "      <th>Month_of_absence</th>\n",
       "      <th>Day_of _the_week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation_expense</th>\n",
       "      <th>Distance_from_Residence_to_Work</th>\n",
       "      <th>Service_time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_load</th>\n",
       "      <th>...</th>\n",
       "      <th>Disciplinary_failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social_drinker</th>\n",
       "      <th>Social_smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body_mass_index</th>\n",
       "      <th>Absenteeism_time_in_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Reason_for_absence  Month_of_absence  Day_of _the_week  Seasons  \\\n",
       "0  11                  26                 7                 3        1   \n",
       "1  36                   0                 7                 3        1   \n",
       "2   3                  23                 7                 4        1   \n",
       "3   7                   7                 7                 5        1   \n",
       "4  11                  23                 7                 5        1   \n",
       "\n",
       "   Transportation_expense  Distance_from_Residence_to_Work  Service_time  Age  \\\n",
       "0                     289                               36            13   33   \n",
       "1                     118                               13            18   50   \n",
       "2                     179                               51            18   38   \n",
       "3                     279                                5            14   39   \n",
       "4                     289                               36            13   33   \n",
       "\n",
       "   Work_load   ...  Disciplinary_failure  Education  Son  Social_drinker  \\\n",
       "0     239.554  ...                     0          1    2               1   \n",
       "1     239.554  ...                     1          1    1               1   \n",
       "2     239.554  ...                     0          1    0               1   \n",
       "3     239.554  ...                     0          1    2               1   \n",
       "4     239.554  ...                     0          1    2               1   \n",
       "\n",
       "   Social_smoker  Pet  Weight  Height  Body_mass_index  \\\n",
       "0              0    1      90     172               30   \n",
       "1              0    0      98     178               31   \n",
       "2              0    0      89     170               31   \n",
       "3              1    0      68     168               24   \n",
       "4              0    1      90     172               30   \n",
       "\n",
       "   Absenteeism_time_in_hours  \n",
       "0                          4  \n",
       "1                          0  \n",
       "2                          2  \n",
       "3                          4  \n",
       "4                          2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Absenteeism_at_work.csv\",sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 740 rows and 21 columns. The last column \"Absenteeism time in hours\" in our target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute ID has no predictive value. We are going to drop it. By the time we know the reason for absence, the absence already happened. So, to get a realistic predictive value, we are going to drop \"Reason_for_absence\". We are also going to drop \"Height\" and \"Weight\", because of the collinearity between these two attributes and the attribute \"body mass index\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Delete redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_of_absence</th>\n",
       "      <th>Day_of _the_week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation_expense</th>\n",
       "      <th>Distance_from_Residence_to_Work</th>\n",
       "      <th>Service_time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_load</th>\n",
       "      <th>Hit_target</th>\n",
       "      <th>Disciplinary_failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social_drinker</th>\n",
       "      <th>Social_smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Body_mass_index</th>\n",
       "      <th>Absenteeism_time_in_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>264.604</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>264.604</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>271.219</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>271.219</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>271.219</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month_of_absence  Day_of _the_week  Seasons  Transportation_expense  \\\n",
       "0                   7                 3        1                     289   \n",
       "1                   7                 3        1                     118   \n",
       "2                   7                 4        1                     179   \n",
       "3                   7                 5        1                     279   \n",
       "4                   7                 5        1                     289   \n",
       "..                ...               ...      ...                     ...   \n",
       "735                 7                 3        1                     289   \n",
       "736                 7                 3        1                     235   \n",
       "737                 0                 3        1                     118   \n",
       "738                 0                 4        2                     231   \n",
       "739                 0                 6        3                     179   \n",
       "\n",
       "     Distance_from_Residence_to_Work  Service_time  Age  Work_load   \\\n",
       "0                                 36            13   33     239.554   \n",
       "1                                 13            18   50     239.554   \n",
       "2                                 51            18   38     239.554   \n",
       "3                                  5            14   39     239.554   \n",
       "4                                 36            13   33     239.554   \n",
       "..                               ...           ...  ...         ...   \n",
       "735                               36            13   33     264.604   \n",
       "736                               11            14   37     264.604   \n",
       "737                               14            13   40     271.219   \n",
       "738                               35            14   39     271.219   \n",
       "739                               45            14   53     271.219   \n",
       "\n",
       "     Hit_target  Disciplinary_failure  Education  Son  Social_drinker  \\\n",
       "0            97                     0          1    2               1   \n",
       "1            97                     1          1    1               1   \n",
       "2            97                     0          1    0               1   \n",
       "3            97                     0          1    2               1   \n",
       "4            97                     0          1    2               1   \n",
       "..          ...                   ...        ...  ...             ...   \n",
       "735          93                     0          1    2               1   \n",
       "736          93                     0          3    1               0   \n",
       "737          95                     0          1    1               1   \n",
       "738          95                     0          1    2               1   \n",
       "739          95                     0          1    1               0   \n",
       "\n",
       "     Social_smoker  Pet  Body_mass_index  Absenteeism_time_in_hours  \n",
       "0                0    1               30                          4  \n",
       "1                0    0               31                          0  \n",
       "2                0    0               31                          2  \n",
       "3                1    0               24                          4  \n",
       "4                0    1               30                          2  \n",
       "..             ...  ...              ...                        ...  \n",
       "735              0    1               30                          8  \n",
       "736              0    1               29                          4  \n",
       "737              0    8               34                          0  \n",
       "738              0    2               35                          0  \n",
       "739              0    1               25                          0  \n",
       "\n",
       "[740 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop([\"ID\",\"Reason_for_absence\",\"Height\",\"Weight\"],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Create labels for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlier_label\n",
       "0                1\n",
       "1                1\n",
       "2                1\n",
       "3                1\n",
       "4                1\n",
       "..             ...\n",
       "735              1\n",
       "736              1\n",
       "737             -1\n",
       "738              1\n",
       "739              1\n",
       "\n",
       "[740 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the outliers from the predictor variables\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "#clf = IsolationForest(random_state=0).fit(df)\n",
    "#outlier_label=pd.DataFrame(clf.predict(df))\n",
    "#outlier_label=outlier_label.rename(columns={0:\"outlier_label\"})\n",
    "#outlier_label\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "clf = EllipticEnvelope(random_state=0)\n",
    "outlier = pd.DataFrame(clf.fit_predict(df))\n",
    "outlier_label=outlier.rename(columns={0:\"outlier_label\"})\n",
    "outlier_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_of_absence</th>\n",
       "      <th>Day_of _the_week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation_expense</th>\n",
       "      <th>Distance_from_Residence_to_Work</th>\n",
       "      <th>Service_time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_load</th>\n",
       "      <th>Hit_target</th>\n",
       "      <th>Disciplinary_failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social_drinker</th>\n",
       "      <th>Social_smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Body_mass_index</th>\n",
       "      <th>Absenteeism_time_in_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>264.604</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>264.604</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>264.604</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>271.219</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>271.219</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month_of_absence  Day_of _the_week  Seasons  Transportation_expense  \\\n",
       "0                   7                 3        1                     289   \n",
       "1                   7                 3        1                     118   \n",
       "2                   7                 4        1                     179   \n",
       "3                   7                 5        1                     279   \n",
       "4                   7                 5        1                     289   \n",
       "..                ...               ...      ...                     ...   \n",
       "733                 7                 4        1                     225   \n",
       "735                 7                 3        1                     289   \n",
       "736                 7                 3        1                     235   \n",
       "738                 0                 4        2                     231   \n",
       "739                 0                 6        3                     179   \n",
       "\n",
       "     Distance_from_Residence_to_Work  Service_time  Age  Work_load   \\\n",
       "0                                 36            13   33     239.554   \n",
       "1                                 13            18   50     239.554   \n",
       "2                                 51            18   38     239.554   \n",
       "3                                  5            14   39     239.554   \n",
       "4                                 36            13   33     239.554   \n",
       "..                               ...           ...  ...         ...   \n",
       "733                               26             9   28     264.604   \n",
       "735                               36            13   33     264.604   \n",
       "736                               11            14   37     264.604   \n",
       "738                               35            14   39     271.219   \n",
       "739                               45            14   53     271.219   \n",
       "\n",
       "     Hit_target  Disciplinary_failure  Education  Son  Social_drinker  \\\n",
       "0            97                     0          1    2               1   \n",
       "1            97                     1          1    1               1   \n",
       "2            97                     0          1    0               1   \n",
       "3            97                     0          1    2               1   \n",
       "4            97                     0          1    2               1   \n",
       "..          ...                   ...        ...  ...             ...   \n",
       "733          93                     0          1    1               0   \n",
       "735          93                     0          1    2               1   \n",
       "736          93                     0          3    1               0   \n",
       "738          95                     0          1    2               1   \n",
       "739          95                     0          1    1               0   \n",
       "\n",
       "     Social_smoker  Pet  Body_mass_index  Absenteeism_time_in_hours  \n",
       "0                0    1               30                          4  \n",
       "1                0    0               31                          0  \n",
       "2                0    0               31                          2  \n",
       "3                1    0               24                          4  \n",
       "4                0    1               30                          2  \n",
       "..             ...  ...              ...                        ...  \n",
       "733              0    2               24                          8  \n",
       "735              0    1               30                          8  \n",
       "736              0    1               29                          4  \n",
       "738              0    2               35                          0  \n",
       "739              0    1               25                          0  \n",
       "\n",
       "[666 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the predictor variables and the outlier column. \n",
    "df = pd.concat([df,outlier_label], axis=1, sort=False)\n",
    "df=df.loc[df[\"outlier_label\"] == 1]\n",
    "df=df.drop([\"outlier_label\"],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm removed 74 (= 740 - 666) outlier rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_of_absence</th>\n",
       "      <th>Day_of _the_week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation_expense</th>\n",
       "      <th>Distance_from_Residence_to_Work</th>\n",
       "      <th>Service_time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_load</th>\n",
       "      <th>Hit_target</th>\n",
       "      <th>Disciplinary_failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social_drinker</th>\n",
       "      <th>Social_smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Body_mass_index</th>\n",
       "      <th>Absenteeism_time_in_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>1.034331</td>\n",
       "      <td>0.538981</td>\n",
       "      <td>0.092487</td>\n",
       "      <td>-0.511142</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>0.732319</td>\n",
       "      <td>-0.213123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>-1.461871</td>\n",
       "      <td>-1.080182</td>\n",
       "      <td>1.290865</td>\n",
       "      <td>2.093336</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>4.183300</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>-0.621699</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>-0.762747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>-0.571413</td>\n",
       "      <td>1.594958</td>\n",
       "      <td>1.290865</td>\n",
       "      <td>0.254881</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>-0.973826</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>-0.621699</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>-0.487935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.831029</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>0.888354</td>\n",
       "      <td>-1.643370</td>\n",
       "      <td>0.332163</td>\n",
       "      <td>0.408085</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>3.400888</td>\n",
       "      <td>-0.621699</td>\n",
       "      <td>-0.673902</td>\n",
       "      <td>-0.213123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.831029</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>1.034331</td>\n",
       "      <td>0.538981</td>\n",
       "      <td>0.092487</td>\n",
       "      <td>-0.511142</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>0.732319</td>\n",
       "      <td>-0.487935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>-0.165003</td>\n",
       "      <td>-0.866215</td>\n",
       "      <td>-1.277165</td>\n",
       "      <td>-0.181301</td>\n",
       "      <td>-0.398650</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>-1.078118</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>1.194316</td>\n",
       "      <td>-0.673902</td>\n",
       "      <td>0.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>1.034331</td>\n",
       "      <td>0.538981</td>\n",
       "      <td>0.092487</td>\n",
       "      <td>-0.511142</td>\n",
       "      <td>-0.181301</td>\n",
       "      <td>-0.398650</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>0.732319</td>\n",
       "      <td>0.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.205495</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>0.246056</td>\n",
       "      <td>-1.220979</td>\n",
       "      <td>0.332163</td>\n",
       "      <td>0.101676</td>\n",
       "      <td>-0.181301</td>\n",
       "      <td>-0.398650</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>2.621856</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>-1.078118</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>0.497949</td>\n",
       "      <td>-0.213123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>-1.824204</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>-0.503000</td>\n",
       "      <td>0.187666</td>\n",
       "      <td>0.468583</td>\n",
       "      <td>0.332163</td>\n",
       "      <td>0.408085</td>\n",
       "      <td>-0.011213</td>\n",
       "      <td>0.123476</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>1.194316</td>\n",
       "      <td>1.904170</td>\n",
       "      <td>-0.762747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>-1.824204</td>\n",
       "      <td>1.551686</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>-0.571413</td>\n",
       "      <td>1.172567</td>\n",
       "      <td>0.332163</td>\n",
       "      <td>2.552950</td>\n",
       "      <td>-0.011213</td>\n",
       "      <td>0.123476</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433535</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>-1.078118</td>\n",
       "      <td>-0.294041</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>-0.439532</td>\n",
       "      <td>-0.762747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month_of_absence  Day_of _the_week   Seasons  Transportation_expense  \\\n",
       "0            0.205495         -0.610287 -1.408399                1.034331   \n",
       "1            0.205495         -0.610287 -1.408399               -1.461871   \n",
       "2            0.205495          0.110371 -1.408399               -0.571413   \n",
       "3            0.205495          0.831029 -1.408399                0.888354   \n",
       "4            0.205495          0.831029 -1.408399                1.034331   \n",
       "..                ...               ...       ...                     ...   \n",
       "661          0.205495          0.110371 -1.408399                0.100080   \n",
       "662          0.205495         -0.610287 -1.408399                1.034331   \n",
       "663          0.205495         -0.610287 -1.408399                0.246056   \n",
       "664         -1.824204          0.110371 -0.503000                0.187666   \n",
       "665         -1.824204          1.551686  0.402400               -0.571413   \n",
       "\n",
       "     Distance_from_Residence_to_Work  Service_time       Age  Work_load   \\\n",
       "0                           0.538981      0.092487 -0.511142   -0.825400   \n",
       "1                          -1.080182      1.290865  2.093336   -0.825400   \n",
       "2                           1.594958      1.290865  0.254881   -0.825400   \n",
       "3                          -1.643370      0.332163  0.408085   -0.825400   \n",
       "4                           0.538981      0.092487 -0.511142   -0.825400   \n",
       "..                               ...           ...       ...         ...   \n",
       "661                        -0.165003     -0.866215 -1.277165   -0.181301   \n",
       "662                         0.538981      0.092487 -0.511142   -0.181301   \n",
       "663                        -1.220979      0.332163  0.101676   -0.181301   \n",
       "664                         0.468583      0.332163  0.408085   -0.011213   \n",
       "665                         1.172567      0.332163  2.552950   -0.011213   \n",
       "\n",
       "     Hit_target  Disciplinary_failure  Education       Son  Social_drinker  \\\n",
       "0      0.645601             -0.239046  -0.433535  1.397538        0.927543   \n",
       "1      0.645601              4.183300  -0.433535  0.211856        0.927543   \n",
       "2      0.645601             -0.239046  -0.433535 -0.973826        0.927543   \n",
       "3      0.645601             -0.239046  -0.433535  1.397538        0.927543   \n",
       "4      0.645601             -0.239046  -0.433535  1.397538        0.927543   \n",
       "..          ...                   ...        ...       ...             ...   \n",
       "661   -0.398650             -0.239046  -0.433535  0.211856       -1.078118   \n",
       "662   -0.398650             -0.239046  -0.433535  1.397538        0.927543   \n",
       "663   -0.398650             -0.239046   2.621856  0.211856       -1.078118   \n",
       "664    0.123476             -0.239046  -0.433535  1.397538        0.927543   \n",
       "665    0.123476             -0.239046  -0.433535  0.211856       -1.078118   \n",
       "\n",
       "     Social_smoker       Pet  Body_mass_index  Absenteeism_time_in_hours  \n",
       "0        -0.294041  0.286309         0.732319                  -0.213123  \n",
       "1        -0.294041 -0.621699         0.966689                  -0.762747  \n",
       "2        -0.294041 -0.621699         0.966689                  -0.487935  \n",
       "3         3.400888 -0.621699        -0.673902                  -0.213123  \n",
       "4        -0.294041  0.286309         0.732319                  -0.487935  \n",
       "..             ...       ...              ...                        ...  \n",
       "661      -0.294041  1.194316        -0.673902                   0.336500  \n",
       "662      -0.294041  0.286309         0.732319                   0.336500  \n",
       "663      -0.294041  0.286309         0.497949                  -0.213123  \n",
       "664      -0.294041  1.194316         1.904170                  -0.762747  \n",
       "665      -0.294041  0.286309        -0.439532                  -0.762747  \n",
       "\n",
       "[666 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "names=df.columns\n",
    "scaler=preprocessing.StandardScaler()\n",
    "df=scaler.fit_transform(df)\n",
    "df=pd.DataFrame(df,columns=names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the predictor variables and target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Separate predictors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "X=df.drop([\"Absenteeism_time_in_hours\"],axis=1)\n",
    "y=df[[\"Absenteeism_time_in_hours\"]]\n",
    "print(X.shape[1])\n",
    "print(y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the feature importance scores for each feature. Since the output is numeric, we are going to use the \"f_regression\" algorithm for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.020036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.146526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.478875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.568640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.104047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.174234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.538303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.779030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.143773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.475610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.731091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.117871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.047512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.940062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.833581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       scores\n",
       "10   0.003096\n",
       "13   0.020036\n",
       "5    0.146526\n",
       "8    0.478875\n",
       "6    0.568640\n",
       "2    1.104047\n",
       "14   1.174234\n",
       "15   1.538303\n",
       "0    1.779030\n",
       "3    2.143773\n",
       "4    2.475610\n",
       "11   3.731091\n",
       "12   4.117871\n",
       "7    5.047512\n",
       "1   15.940062\n",
       "9   22.833581"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the libraries.\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# feature extraction. We are going to output the selection scores for all features and select the features with the highest scores.\n",
    "test = SelectKBest(score_func=f_regression, k=16)\n",
    "fit = test.fit(X, y)\n",
    "features = fit.transform(X)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "scores=fit.scores_\n",
    "scores=pd.DataFrame(scores)\n",
    "scores=scores.rename(columns={0:\"scores\"})\n",
    "scores.sort_values(by=[\"scores\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) The most important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important feature is:  Disciplinary_failure\n"
     ]
    }
   ],
   "source": [
    "print(\"The most important feature is: \",X.iloc[:,9].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) The least important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least important feature is:  Education\n"
     ]
    }
   ],
   "source": [
    "print(\"The least important feature is: \",X.iloc[:,10].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) The 12 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Disciplinary_failure', 'Day_of _the_week', 'Work_load ',\n",
      "       'Social_drinker', 'Son', 'Distance_from_Residence_to_Work',\n",
      "       'Transportation_expense', 'Month_of_absence', 'Body_mass_index', 'Pet',\n",
      "       'Seasons', 'Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(X.iloc[:,[1,11,12,4,7,9,0,10,14,13,3,6]].columns)\n",
    "print(X.iloc[:,[9,1,7,12,11,4,3,0,15,14,2,6]].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) Select the 12 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disciplinary_failure</th>\n",
       "      <th>Day_of _the_week</th>\n",
       "      <th>Work_load</th>\n",
       "      <th>Social_drinker</th>\n",
       "      <th>Son</th>\n",
       "      <th>Distance_from_Residence_to_Work</th>\n",
       "      <th>Transportation_expense</th>\n",
       "      <th>Month_of_absence</th>\n",
       "      <th>Body_mass_index</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.538981</td>\n",
       "      <td>1.034331</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.732319</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>-0.511142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.183300</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>-1.080182</td>\n",
       "      <td>-1.461871</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>-0.621699</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>2.093336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.973826</td>\n",
       "      <td>1.594958</td>\n",
       "      <td>-0.571413</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>-0.621699</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>0.254881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.831029</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>-1.643370</td>\n",
       "      <td>0.888354</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>-0.673902</td>\n",
       "      <td>-0.621699</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>0.408085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.831029</td>\n",
       "      <td>-0.825400</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.538981</td>\n",
       "      <td>1.034331</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.732319</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>-0.511142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>-0.181301</td>\n",
       "      <td>-1.078118</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>-0.165003</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>-0.673902</td>\n",
       "      <td>1.194316</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>-1.277165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-0.181301</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.538981</td>\n",
       "      <td>1.034331</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.732319</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>-0.511142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.610287</td>\n",
       "      <td>-0.181301</td>\n",
       "      <td>-1.078118</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>-1.220979</td>\n",
       "      <td>0.246056</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.497949</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>-1.408399</td>\n",
       "      <td>0.101676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>-0.011213</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>1.397538</td>\n",
       "      <td>0.468583</td>\n",
       "      <td>0.187666</td>\n",
       "      <td>-1.824204</td>\n",
       "      <td>1.904170</td>\n",
       "      <td>1.194316</td>\n",
       "      <td>-0.503000</td>\n",
       "      <td>0.408085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>1.551686</td>\n",
       "      <td>-0.011213</td>\n",
       "      <td>-1.078118</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>1.172567</td>\n",
       "      <td>-0.571413</td>\n",
       "      <td>-1.824204</td>\n",
       "      <td>-0.439532</td>\n",
       "      <td>0.286309</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>2.552950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Disciplinary_failure  Day_of _the_week  Work_load   Social_drinker  \\\n",
       "0               -0.239046         -0.610287   -0.825400        0.927543   \n",
       "1                4.183300         -0.610287   -0.825400        0.927543   \n",
       "2               -0.239046          0.110371   -0.825400        0.927543   \n",
       "3               -0.239046          0.831029   -0.825400        0.927543   \n",
       "4               -0.239046          0.831029   -0.825400        0.927543   \n",
       "..                    ...               ...         ...             ...   \n",
       "661             -0.239046          0.110371   -0.181301       -1.078118   \n",
       "662             -0.239046         -0.610287   -0.181301        0.927543   \n",
       "663             -0.239046         -0.610287   -0.181301       -1.078118   \n",
       "664             -0.239046          0.110371   -0.011213        0.927543   \n",
       "665             -0.239046          1.551686   -0.011213       -1.078118   \n",
       "\n",
       "          Son  Distance_from_Residence_to_Work  Transportation_expense  \\\n",
       "0    1.397538                         0.538981                1.034331   \n",
       "1    0.211856                        -1.080182               -1.461871   \n",
       "2   -0.973826                         1.594958               -0.571413   \n",
       "3    1.397538                        -1.643370                0.888354   \n",
       "4    1.397538                         0.538981                1.034331   \n",
       "..        ...                              ...                     ...   \n",
       "661  0.211856                        -0.165003                0.100080   \n",
       "662  1.397538                         0.538981                1.034331   \n",
       "663  0.211856                        -1.220979                0.246056   \n",
       "664  1.397538                         0.468583                0.187666   \n",
       "665  0.211856                         1.172567               -0.571413   \n",
       "\n",
       "     Month_of_absence  Body_mass_index       Pet   Seasons       Age  \n",
       "0            0.205495         0.732319  0.286309 -1.408399 -0.511142  \n",
       "1            0.205495         0.966689 -0.621699 -1.408399  2.093336  \n",
       "2            0.205495         0.966689 -0.621699 -1.408399  0.254881  \n",
       "3            0.205495        -0.673902 -0.621699 -1.408399  0.408085  \n",
       "4            0.205495         0.732319  0.286309 -1.408399 -0.511142  \n",
       "..                ...              ...       ...       ...       ...  \n",
       "661          0.205495        -0.673902  1.194316 -1.408399 -1.277165  \n",
       "662          0.205495         0.732319  0.286309 -1.408399 -0.511142  \n",
       "663          0.205495         0.497949  0.286309 -1.408399  0.101676  \n",
       "664         -1.824204         1.904170  1.194316 -0.503000  0.408085  \n",
       "665         -1.824204        -0.439532  0.286309  0.402400  2.552950  \n",
       "\n",
       "[666 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X=X.iloc[:,[1,9,11,4,6,12,15,10,14,3,8,7]]\n",
    "X=X.iloc[:,[9,1,7,12,11,4,3,0,15,14,2,6]]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now processed. Let's build the regression model using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) Import the libraries for TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(13) Build the multiple linear regression model with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0, loss = 2257.45, A = [[-0.075  0.066  0.665  0.208  0.302 -0.635  0.023  0.292  0.302  0.584\n",
      "   0.167  0.41 ]], b = 0.661201\n",
      "t = 1000, loss = 695.164, A = [[-0.14  -0.156  0.136 -0.08   0.091 -0.015 -0.059 -0.049 -0.071  0.095\n",
      "   0.02   0.021]], b = 0.0607299\n",
      "t = 2000, loss = 681.631, A = [[-0.136 -0.15   0.077 -0.131  0.087  0.115 -0.109 -0.038 -0.008  0.046\n",
      "   0.023  0.017]], b = 0.000364673\n",
      "t = 3000, loss = 681.604, A = [[-0.136 -0.15   0.076 -0.133  0.087  0.121 -0.11  -0.036 -0.003  0.042\n",
      "   0.023  0.017]], b = 2.14451e-08\n",
      "t = 4000, loss = 681.604, A = [[-0.136 -0.15   0.076 -0.133  0.087  0.121 -0.11  -0.036 -0.003  0.042\n",
      "   0.023  0.017]], b = -1.83518e-10\n",
      "t = 5000, loss = 681.604, A = [[-0.136 -0.15   0.076 -0.133  0.087  0.121 -0.11  -0.036 -0.003  0.042\n",
      "   0.023  0.017]], b = -6.59867e-09\n",
      "t = 6000, loss = 681.604, A = [[-0.136 -0.15   0.076 -0.133  0.087  0.121 -0.11  -0.036 -0.003  0.042\n",
      "   0.023  0.017]], b = -7.82964e-09\n",
      "t = 7000, loss = 681.604, A = [[-0.136 -0.15   0.076 -0.133  0.087  0.121 -0.11  -0.036 -0.003  0.042\n",
      "   0.023  0.017]], b = -1.52899e-08\n",
      "t = 8000, loss = 681.604, A = [[-0.136 -0.15   0.076 -0.133  0.087  0.121 -0.11  -0.036 -0.003  0.042\n",
      "   0.023  0.017]], b = -1.13494e-08\n",
      "t = 9000, loss = 681.604, A = [[-0.136 -0.15   0.076 -0.133  0.087  0.121 -0.11  -0.036 -0.003  0.042\n",
      "   0.023  0.017]], b = -8.99285e-09\n"
     ]
    }
   ],
   "source": [
    "X=np.matrix(X.values)\n",
    "y=np.matrix(y.values)\n",
    "\n",
    "x_data=X.transpose()\n",
    "y_data=y.transpose()\n",
    "\n",
    "n=12\n",
    "\n",
    "# Define data placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(n, None))\n",
    "y = tf.placeholder(tf.float32, shape=(1, None))\n",
    "\n",
    "# Define trainable variables\n",
    "A = tf.get_variable(\"A\", shape=(1, n))\n",
    "b = tf.get_variable(\"b\", shape=())\n",
    "\n",
    "# Define model output\n",
    "y_predicted = tf.matmul(A, x) + b\n",
    "\n",
    "# Define the loss function\n",
    "L = tf.reduce_sum((y_predicted - y)**2)\n",
    "\n",
    "# Define optimizer object\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(L)\n",
    "\n",
    "# Create a session and initialize variables\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# Main optimization loop\n",
    "loss_values=[]\n",
    "for t in range(10000):\n",
    "    _, current_loss, current_A, current_b = session.run([optimizer, L, A, b], feed_dict={\n",
    "        x: x_data,\n",
    "        y: y_data\n",
    "    })\n",
    "    loss_values.append(current_loss)\n",
    "    if t %1000 == 0:\n",
    "        print(\"t = %g, loss = %g, A = %s, b = %g\" % (t, current_loss, str(current_A), current_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(14) Visulize the loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6eb7d67e48>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_values, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(15) Compute the correlation between the actual y values and the predicted y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.281],\n",
       "       [0.281, 1.   ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.asarray(X)\n",
    "X=X.T\n",
    "\n",
    "A =np.array([[-0.136, -0.15 ,  0.076, -0.133 , 0.087 , 0.121, -0.11 , -0.036, -0.003 , 0.042,\n",
    "   0.023 , 0.017]])\n",
    "b=-1.36056e-08\n",
    "y_pred=A@X+b\n",
    "coeff=np.corrcoef(y_data,y_pred)\n",
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Neural_network_regression_with_Keras'></a>\n",
    "<center><font size=5> II. Neural network regression model with Keras </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient between the predicted absenteeism hours and the actual hours is only 0.281. The multiple linear regression model with TensorFlow did not produce very satisfactory output. Let's try a neural network regression model with Keras. **To do that, we are going to re-run the code blocks (1) - (11) and skip (12) - (15).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(16) Import libraries for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(16) Define the neural network regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=X.shape[1]\n",
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(110, activation='relu', input_shape=(num_cols,)))\n",
    "    model.add(Dense(110, activation='relu'))\n",
    "    model.add(Dense(110, activation ='relu'))\n",
    "    model.add(Dense(110,activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(17) Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(18) Fit the neural network regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 432 samples, validate on 234 samples\n",
      "Epoch 1/12\n",
      " - 0s - loss: 0.5971 - val_loss: 0.6678\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.5758 - val_loss: 0.6290\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.5494 - val_loss: 0.6869\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.5386 - val_loss: 0.7075\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.5002 - val_loss: 0.6722\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.5117 - val_loss: 0.7551\n",
      "Epoch 7/12\n",
      " - 1s - loss: 0.5366 - val_loss: 0.6593\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.6053 - val_loss: 0.8618\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.4861 - val_loss: 0.6383\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.4511 - val_loss: 0.6955\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.4213 - val_loss: 0.6936\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.4181 - val_loss: 0.5846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa44e11bba8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_split=0.35, epochs=12, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(19) Visualize how the predicted absenteeism hours compare to the actual absenteeism hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_pred=model.predict(X)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(y, y_pred,color='blue')\n",
    "plt.title('Actual absenteeism time in hours vs. predicted absenteeism time in hours')\n",
    "plt.xlabel('Actual absenteeism time in hours')\n",
    "plt.ylabel('Predicted absenteeism time in hours')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a very bold try. The \"Absenteeims at work\" dataset was not meant to be used for building regression model. It was originally used for post-graduate research at Universidade Nove de Julho in Brazil. The associated machine learning tasks are clustering and classification. There have been lots of research papers about researh on this dataset. The researchers categorized the target attribute \"absenteeism time in hour\" into several classes and built classification models. There was one papaer that the researched categoried target attribute into 3 classes (=0, > 0 but <= 10, >10) and claimed that by using a Random Forest classification model, the research attained an accuracy of 91%. There was also another paper in which the researcher categorized the target attribute into 5 classes (hours < 2, 2 <= hours <5, 5 <= hours <10, 10 <= hours < 80, hours >= 80) and claimed that the neural network model built this way had an accuracy of 58%. Neither research attained very satisfactory ressults. The first research classified the target attribute too  broadly and thus had limited predictive values. The second research did a more detailed classification but the accuracy was rather low. \n",
    "\n",
    "It seems that the main challenge with this dataset is that you either have to sacrifice practical predictive values for high accuracy or sacrifice high accuracy for more practical predictive values.\n",
    "\n",
    "**I am going to make two more bold tries: (1) build a clustering model and (2) a classification model and see if I can do better than the researchers who had published papaers on research done on this dataset.**\n",
    "\n",
    "I did a presenetation on this dataset for an online course at Coursera that I am currently enrolled in. My peers from that course commented that the subject was not important enough, would not generate big business values and that they were not convinced. They might be business people with no (or very limited) background in data science or machine learning. The subject (and the \"absenteeism at work\" dataset as well) is obviously very well-known in the machine learning research community or the academic community. The dataset itself is intriguing in the sense that it seems to present insurmountable challenge for the researchers. As for the subject \"Absenteeism at work\", it IS a huge human resource management challlenge for almost every organization. (Of course, I would not engage in such arguments with my peers. I prefer to devote my time to tackcle the tasks on hand. **I think my work will speak for itself.^^_**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='K_Means_Clustering'></a>\n",
    "<center> <font size =5> III. K-Means Clustering </font><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20) K-Means on the cleaned dataset with outlier removal, feature selection and standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.1367961629798646\n",
      "For n_clusters = 3 The average silhouette_score is : 0.15007951698757202\n",
      "For n_clusters = 4 The average silhouette_score is : 0.17519944116069275\n",
      "For n_clusters = 5 The average silhouette_score is : 0.1784301077650526\n",
      "For n_clusters = 6 The average silhouette_score is : 0.1858612740395457\n",
      "For n_clusters = 7 The average silhouette_score is : 0.2061561360511031\n",
      "For n_clusters = 8 The average silhouette_score is : 0.19258632091931616\n",
      "For n_clusters = 9 The average silhouette_score is : 0.20721602884872353\n",
      "For n_clusters = 10 The average silhouette_score is : 0.20457870460032523\n",
      "For n_clusters = 11 The average silhouette_score is : 0.20405707140462487\n",
      "For n_clusters = 12 The average silhouette_score is : 0.22681349575806198\n",
      "For n_clusters = 13 The average silhouette_score is : 0.2195322287776138\n",
      "For n_clusters = 14 The average silhouette_score is : 0.2270257743991643\n",
      "For n_clusters = 15 The average silhouette_score is : 0.23916079913919716\n",
      "For n_clusters = 16 The average silhouette_score is : 0.23289160018802257\n",
      "For n_clusters = 17 The average silhouette_score is : 0.2381585534856572\n",
      "For n_clusters = 18 The average silhouette_score is : 0.21729770656111136\n",
      "For n_clusters = 19 The average silhouette_score is : 0.22764142897047449\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average silhouette score to determine the \"good number\" of clusters.\n",
    "df_cleaned=pd.concat([X,y],axis=1)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "for n_clusters in range(2,20):\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(df_cleaned)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(df_cleaned, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(df_cleaned, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette scors for n = 2 to 19 are all very low. It seems that we are not going to get a good number of clusters on the cleaned dataset with outliers removal, feature selection and standardization. Let's try K-means on the original dataset. A biggest challenge this data set presents for K-Means clustering analysis is that a lot of its variables are indeed categorical, although they have been given integer labels. The K-Means algorithm that is based on Euclidean distance is not really meaningful with categorical variables, but assigning integer labels to those variables still allows us to use the algorithm to perform K-Means clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(21) K-Means on the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.14982941294759924\n",
      "For n_clusters = 3 The average silhouette_score is : 0.15117946637496227\n",
      "For n_clusters = 4 The average silhouette_score is : 0.16557281346641337\n",
      "For n_clusters = 5 The average silhouette_score is : 0.16332873706040926\n",
      "For n_clusters = 6 The average silhouette_score is : 0.1890021936122242\n",
      "For n_clusters = 7 The average silhouette_score is : 0.20238195267956527\n",
      "For n_clusters = 8 The average silhouette_score is : 0.19825248922612987\n",
      "For n_clusters = 9 The average silhouette_score is : 0.20635035288518652\n",
      "For n_clusters = 10 The average silhouette_score is : 0.2284563099055256\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average silhouette score to determine the \"good number\" of clusters.\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "range_n_clusters = [2, 3, 4, 5, 6,7,8,9,10]\n",
    "for n_clusters in range_n_clusters:\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(df)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(df, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(df, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No luck with the original dataset either. Is it just not possible to perform K-means clustering on the \"Absenteeism at work\" dataset? No. silhouette score is NOT the only way to determine what is the optimal number of clusters. The optimal number of clusters depends on the purpose of the task on hand. I personally have seen cases where the optimal number of clusters determined by the algorithm is not meaningful for the purpose of task on hand. Such is especially true in business settings. The optimal number of cluster is often determined by whether clustering the data in a certain way will improve operational efficiency and whether it is practical from managerial and executional perspective. If it is not practical from managerial and/or executional perspectives, it is essentially useless. So, the \"Absenteeism at work\" dataset is not completely hopeless. Instead of relying on the algorithm to determine what should be the number of clusters, we are going to manually cluster the dataset. For example, we will cluster employees who were never absent together, employees with absence time less than or equal to 8 hours in another group, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Multilabel_classification_with_TensorFlow'></a>\n",
    "<center> <font size =5 > IV. The multilabel classification model with TensorFlow. </font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mannually cluster the \"Absenteeism at work\" dataset, I am going to write some SQL queries. In order to be able to write SQL queries in this Jupyter notebook, I need to upload the dataset to IBM's Db2 and connect to my IBM Db2 account. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(22) Import IBM Db and load the SQL extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_db\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(23) Connect to the IBM database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have to clear this cell and its output, since it contains everything neede to connect to IBM's Db2 through my account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the following criteria to manually cluster the dataset: <br>\n",
    "- Absenteeism hours = 0: 0\n",
    "- 0 < Absenteeism hours <= 8: 1\n",
    "- 8 < Absenteeism hours <= 16: 2\n",
    "- 16 < Absenteeism hours <=24: 3\n",
    "- 24 < Absenteeism hours <= 32: 4\n",
    "- 32 < Absenteeism hours <= 40: 5\n",
    "- Absenteeism hours > 40: 6\n",
    "\n",
    "So, there will be 7 classes: 0,1,2,3,4,5,6,7. Each class represents the number of 8-hour workdays that an employee was absent for. There are a few employees who were absent for more than six 8-hour workdays.However, dividing the dataset in a way that is unnecessarily detailed might make the model more difficult to train and compromise accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(24) Write the SQL query to manually cluster the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = %sql SELECT *, CASE WHEN Absenteeism_time_in_hours= 0 THEN 0 WHEN AND(Absenteeism_time_in_hours>0,Absenteeism_time_in_hours<=8) THEN 1 WHEN AND(Absenteeism_time_in_hours>8,Absenteeism_time_in_hours<=16) THEN 2 WHEN AND(Absenteeism_time_in_hours>16, Absenteeism_time_in_hours<=24) THEN 3 WHEN AND(Absenteeism_time_in_hours>24, Absenteeism_time_in_hours<=32) THEN 4 WHEN AND(Absenteeism_time_in_hours>32, Absenteeism_time_in_hours<=40) THEN 5 ELSE 6 END AS Absenteeism_category from Absenteeism_at_work\n",
    "# I cleared the output of this cell, since it contains everything needed to connect to Db2 through my account as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(25) Output the query result to .csv format file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"./files/df_new.csv\">CSV results</a>"
      ],
      "text/plain": [
       "CSV results at /resources/labs/ML0120EN/df_new.csv"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.csv(\"df_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(26) Load the clustered dataset as pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reason_for_absence</th>\n",
       "      <th>month_of_absence</th>\n",
       "      <th>day_of__the_week</th>\n",
       "      <th>seasons</th>\n",
       "      <th>transportation_expense</th>\n",
       "      <th>distance_from_residence_to_work</th>\n",
       "      <th>service_time</th>\n",
       "      <th>age</th>\n",
       "      <th>work_load</th>\n",
       "      <th>...</th>\n",
       "      <th>education</th>\n",
       "      <th>son</th>\n",
       "      <th>social_drinker</th>\n",
       "      <th>social_smoker</th>\n",
       "      <th>pet</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>absenteeism_time_in_hours</th>\n",
       "      <th>absenteeism_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  reason_for_absence  month_of_absence  day_of__the_week  seasons  \\\n",
       "0  11                  26                 7                 3        1   \n",
       "1  36                   0                 7                 3        1   \n",
       "2   3                  23                 7                 4        1   \n",
       "3   7                   7                 7                 5        1   \n",
       "4  11                  23                 7                 5        1   \n",
       "\n",
       "   transportation_expense  distance_from_residence_to_work  service_time  age  \\\n",
       "0                     289                               36            13   33   \n",
       "1                     118                               13            18   50   \n",
       "2                     179                               51            18   38   \n",
       "3                     279                                5            14   39   \n",
       "4                     289                               36            13   33   \n",
       "\n",
       "   work_load  ...  education  son  social_drinker  social_smoker  pet  weight  \\\n",
       "0    239.554  ...          1    2               1              0    1      90   \n",
       "1    239.554  ...          1    1               1              0    0      98   \n",
       "2    239.554  ...          1    0               1              0    0      89   \n",
       "3    239.554  ...          1    2               1              1    0      68   \n",
       "4    239.554  ...          1    2               1              0    1      90   \n",
       "\n",
       "   height  body_mass_index  absenteeism_time_in_hours  absenteeism_category  \n",
       "0     172               30                          4                     1  \n",
       "1     178               31                          0                     0  \n",
       "2     170               31                          2                     1  \n",
       "3     168               24                          4                     1  \n",
       "4     172               30                          2                     1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_new=pd.read_csv(\"df_new.csv\")\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a new column \"absenteeism_category\". We do not need the column \"absenteeism_time_in_hours\" anymore. So, we are going to drop that column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(27) Drop the \"Absenteeism_time_in_hours\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to drop the \"id\" column, which has no predictive value. We will drop the \"reason_for_absence\" column as well. By the time we know the reason for absence, the absence would have already happened. So, to get a realistic model with predictive value, we need to drop the \"reason_for_absence\" column as well.Finally, we will also exclude \"Weight\" and \"Height\" because of the collinearity between these two attributes and the attribute \"Body mass index\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_of_absence</th>\n",
       "      <th>day_of__the_week</th>\n",
       "      <th>seasons</th>\n",
       "      <th>transportation_expense</th>\n",
       "      <th>distance_from_residence_to_work</th>\n",
       "      <th>service_time</th>\n",
       "      <th>age</th>\n",
       "      <th>work_load</th>\n",
       "      <th>hit_target</th>\n",
       "      <th>disciplinary_failure</th>\n",
       "      <th>education</th>\n",
       "      <th>son</th>\n",
       "      <th>social_drinker</th>\n",
       "      <th>social_smoker</th>\n",
       "      <th>pet</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>absenteeism_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_of_absence  day_of__the_week  seasons  transportation_expense  \\\n",
       "0                 7                 3        1                     289   \n",
       "1                 7                 3        1                     118   \n",
       "2                 7                 4        1                     179   \n",
       "3                 7                 5        1                     279   \n",
       "4                 7                 5        1                     289   \n",
       "\n",
       "   distance_from_residence_to_work  service_time  age  work_load  hit_target  \\\n",
       "0                               36            13   33    239.554          97   \n",
       "1                               13            18   50    239.554          97   \n",
       "2                               51            18   38    239.554          97   \n",
       "3                                5            14   39    239.554          97   \n",
       "4                               36            13   33    239.554          97   \n",
       "\n",
       "   disciplinary_failure  education  son  social_drinker  social_smoker  pet  \\\n",
       "0                     0          1    2               1              0    1   \n",
       "1                     1          1    1               1              0    0   \n",
       "2                     0          1    0               1              0    0   \n",
       "3                     0          1    2               1              1    0   \n",
       "4                     0          1    2               1              0    1   \n",
       "\n",
       "   body_mass_index  absenteeism_category  \n",
       "0               30                     1  \n",
       "1               31                     0  \n",
       "2               31                     1  \n",
       "3               24                     1  \n",
       "4               30                     1  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new=df_new.drop([\"id\",\"reason_for_absence\",\"absenteeism_time_in_hours\",\"weight\",\"height\"],axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(28) Seperate the predictor variables and the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_X=df_new.drop([\"absenteeism_category\"],axis=1)\n",
    "Y=df_new[[\"absenteeism_category\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(29) Normalize the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_of_absence</th>\n",
       "      <th>day_of__the_week</th>\n",
       "      <th>seasons</th>\n",
       "      <th>transportation_expense</th>\n",
       "      <th>distance_from_residence_to_work</th>\n",
       "      <th>service_time</th>\n",
       "      <th>age</th>\n",
       "      <th>work_load</th>\n",
       "      <th>hit_target</th>\n",
       "      <th>disciplinary_failure</th>\n",
       "      <th>education</th>\n",
       "      <th>son</th>\n",
       "      <th>social_drinker</th>\n",
       "      <th>social_smoker</th>\n",
       "      <th>pet</th>\n",
       "      <th>body_mass_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>1.011408</td>\n",
       "      <td>0.429556</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>-0.532868</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>0.192850</td>\n",
       "      <td>0.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>-1.544379</td>\n",
       "      <td>-1.121694</td>\n",
       "      <td>1.242825</td>\n",
       "      <td>2.092860</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>4.183300</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>-0.566240</td>\n",
       "      <td>1.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>0.059924</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>-0.632665</td>\n",
       "      <td>1.441240</td>\n",
       "      <td>1.242825</td>\n",
       "      <td>0.239405</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>-0.928191</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>-0.566240</td>\n",
       "      <td>1.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>0.763796</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.861947</td>\n",
       "      <td>-1.661258</td>\n",
       "      <td>0.329981</td>\n",
       "      <td>0.393859</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>3.564226</td>\n",
       "      <td>-0.566240</td>\n",
       "      <td>-0.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>0.763796</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>1.011408</td>\n",
       "      <td>0.429556</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>-0.532868</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>0.192850</td>\n",
       "      <td>0.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>1.011408</td>\n",
       "      <td>0.429556</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>-0.532868</td>\n",
       "      <td>-0.176427</td>\n",
       "      <td>-0.420423</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>0.192850</td>\n",
       "      <td>0.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.204318</td>\n",
       "      <td>-1.256585</td>\n",
       "      <td>0.329981</td>\n",
       "      <td>0.084950</td>\n",
       "      <td>-0.176427</td>\n",
       "      <td>-0.420423</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>2.538869</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>-1.145644</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>0.192850</td>\n",
       "      <td>0.542427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>-1.841698</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>-1.544379</td>\n",
       "      <td>-1.054248</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.548314</td>\n",
       "      <td>-0.006949</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>5.506478</td>\n",
       "      <td>1.709954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>-1.841698</td>\n",
       "      <td>0.059924</td>\n",
       "      <td>-0.490149</td>\n",
       "      <td>0.144533</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.329981</td>\n",
       "      <td>0.393859</td>\n",
       "      <td>-0.006949</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>0.951940</td>\n",
       "      <td>1.943459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>-1.841698</td>\n",
       "      <td>1.467667</td>\n",
       "      <td>0.409877</td>\n",
       "      <td>-0.632665</td>\n",
       "      <td>1.036566</td>\n",
       "      <td>0.329981</td>\n",
       "      <td>2.556224</td>\n",
       "      <td>-0.006949</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.433857</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>-1.145644</td>\n",
       "      <td>-0.280566</td>\n",
       "      <td>0.192850</td>\n",
       "      <td>-0.391595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month_of_absence  day_of__the_week   seasons  transportation_expense  \\\n",
       "0            0.196763         -0.643947 -1.390175                1.011408   \n",
       "1            0.196763         -0.643947 -1.390175               -1.544379   \n",
       "2            0.196763          0.059924 -1.390175               -0.632665   \n",
       "3            0.196763          0.763796 -1.390175                0.861947   \n",
       "4            0.196763          0.763796 -1.390175                1.011408   \n",
       "..                ...               ...       ...                     ...   \n",
       "735          0.196763         -0.643947 -1.390175                1.011408   \n",
       "736          0.196763         -0.643947 -1.390175                0.204318   \n",
       "737         -1.841698         -0.643947 -1.390175               -1.544379   \n",
       "738         -1.841698          0.059924 -0.490149                0.144533   \n",
       "739         -1.841698          1.467667  0.409877               -0.632665   \n",
       "\n",
       "     distance_from_residence_to_work  service_time       age  work_load  \\\n",
       "0                           0.429556      0.101770 -0.532868  -0.818212   \n",
       "1                          -1.121694      1.242825  2.092860  -0.818212   \n",
       "2                           1.441240      1.242825  0.239405  -0.818212   \n",
       "3                          -1.661258      0.329981  0.393859  -0.818212   \n",
       "4                           0.429556      0.101770 -0.532868  -0.818212   \n",
       "..                               ...           ...       ...        ...   \n",
       "735                         0.429556      0.101770 -0.532868  -0.176427   \n",
       "736                        -1.256585      0.329981  0.084950  -0.176427   \n",
       "737                        -1.054248      0.101770  0.548314  -0.006949   \n",
       "738                         0.362110      0.329981  0.393859  -0.006949   \n",
       "739                         1.036566      0.329981  2.556224  -0.006949   \n",
       "\n",
       "     hit_target  disciplinary_failure  education       son  social_drinker  \\\n",
       "0      0.638686             -0.239046  -0.433857  0.893723        0.872872   \n",
       "1      0.638686              4.183300  -0.433857 -0.017234        0.872872   \n",
       "2      0.638686             -0.239046  -0.433857 -0.928191        0.872872   \n",
       "3      0.638686             -0.239046  -0.433857  0.893723        0.872872   \n",
       "4      0.638686             -0.239046  -0.433857  0.893723        0.872872   \n",
       "..          ...                   ...        ...       ...             ...   \n",
       "735   -0.420423             -0.239046  -0.433857  0.893723        0.872872   \n",
       "736   -0.420423             -0.239046   2.538869 -0.017234       -1.145644   \n",
       "737    0.109131             -0.239046  -0.433857 -0.017234        0.872872   \n",
       "738    0.109131             -0.239046  -0.433857  0.893723        0.872872   \n",
       "739    0.109131             -0.239046  -0.433857 -0.017234       -1.145644   \n",
       "\n",
       "     social_smoker       pet  body_mass_index  \n",
       "0        -0.280566  0.192850         0.775932  \n",
       "1        -0.280566 -0.566240         1.009438  \n",
       "2        -0.280566 -0.566240         1.009438  \n",
       "3         3.564226 -0.566240        -0.625100  \n",
       "4        -0.280566  0.192850         0.775932  \n",
       "..             ...       ...              ...  \n",
       "735      -0.280566  0.192850         0.775932  \n",
       "736      -0.280566  0.192850         0.542427  \n",
       "737      -0.280566  5.506478         1.709954  \n",
       "738      -0.280566  0.951940         1.943459  \n",
       "739      -0.280566  0.192850        -0.391595  \n",
       "\n",
       "[740 rows x 16 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "names=df_new_X.columns\n",
    "scaler=preprocessing.StandardScaler()\n",
    "X=scaler.fit_transform(df_new_X)\n",
    "X=pd.DataFrame(X,columns=names)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will not use any outlier removal algorithm this time. The way that the original dataset was clustered meant to include all data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(30) Feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.727051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.268992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.307315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.394055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.549275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.784723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.009708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.019795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.038688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.265621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.589357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.794711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.808771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.395234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.635687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1149.027027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scores\n",
       "5      0.727051\n",
       "10     1.268992\n",
       "0      1.307315\n",
       "14     1.394055\n",
       "3      1.549275\n",
       "13     1.784723\n",
       "15     2.009708\n",
       "4      2.019795\n",
       "11     2.038688\n",
       "12     2.265621\n",
       "2      2.589357\n",
       "1      2.794711\n",
       "6      2.808771\n",
       "8      3.395234\n",
       "7      3.635687\n",
       "9   1149.027027"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the libraries.\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# feature extraction. We are going to output the selection scores for all features and select the features with the highest scores.\n",
    "test = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "fit = test.fit(X, Y)\n",
    "features = fit.transform(X)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "# Sort the feature scores in ascending order.\n",
    "scores=fit.scores_\n",
    "scores=pd.DataFrame(scores)\n",
    "scores=scores.rename(columns={0:\"scores\"})\n",
    "scores.sort_values(by=[\"scores\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature is the one with column index 9. The least important feature is the one with column index 5. We can output the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important feature is:  disciplinary_failure\n"
     ]
    }
   ],
   "source": [
    "print(\"The most important feature is: \",X.iloc[:,9].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least important feature is:  service_time\n"
     ]
    }
   ],
   "source": [
    "print(\"The least important feature is: \",X.iloc[:,5].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(31) Select the 10 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disciplinary_failure</th>\n",
       "      <th>work_load</th>\n",
       "      <th>hit_target</th>\n",
       "      <th>age</th>\n",
       "      <th>day_of__the_week</th>\n",
       "      <th>seasons</th>\n",
       "      <th>social_drinker</th>\n",
       "      <th>son</th>\n",
       "      <th>distance_from_residence_to_work</th>\n",
       "      <th>body_mass_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>-0.532868</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.429556</td>\n",
       "      <td>0.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.183300</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>2.092860</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>-1.121694</td>\n",
       "      <td>1.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>0.239405</td>\n",
       "      <td>0.059924</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.928191</td>\n",
       "      <td>1.441240</td>\n",
       "      <td>1.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>0.393859</td>\n",
       "      <td>0.763796</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>-1.661258</td>\n",
       "      <td>-0.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.818212</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>-0.532868</td>\n",
       "      <td>0.763796</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.429556</td>\n",
       "      <td>0.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.176427</td>\n",
       "      <td>-0.420423</td>\n",
       "      <td>-0.532868</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.429556</td>\n",
       "      <td>0.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.176427</td>\n",
       "      <td>-0.420423</td>\n",
       "      <td>0.084950</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>-1.145644</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>-1.256585</td>\n",
       "      <td>0.542427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.006949</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>0.548314</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>-1.390175</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>-1.054248</td>\n",
       "      <td>1.709954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.006949</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>0.393859</td>\n",
       "      <td>0.059924</td>\n",
       "      <td>-0.490149</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>1.943459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.006949</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>2.556224</td>\n",
       "      <td>1.467667</td>\n",
       "      <td>0.409877</td>\n",
       "      <td>-1.145644</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>1.036566</td>\n",
       "      <td>-0.391595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     disciplinary_failure  work_load  hit_target       age  day_of__the_week  \\\n",
       "0               -0.239046  -0.818212    0.638686 -0.532868         -0.643947   \n",
       "1                4.183300  -0.818212    0.638686  2.092860         -0.643947   \n",
       "2               -0.239046  -0.818212    0.638686  0.239405          0.059924   \n",
       "3               -0.239046  -0.818212    0.638686  0.393859          0.763796   \n",
       "4               -0.239046  -0.818212    0.638686 -0.532868          0.763796   \n",
       "..                    ...        ...         ...       ...               ...   \n",
       "735             -0.239046  -0.176427   -0.420423 -0.532868         -0.643947   \n",
       "736             -0.239046  -0.176427   -0.420423  0.084950         -0.643947   \n",
       "737             -0.239046  -0.006949    0.109131  0.548314         -0.643947   \n",
       "738             -0.239046  -0.006949    0.109131  0.393859          0.059924   \n",
       "739             -0.239046  -0.006949    0.109131  2.556224          1.467667   \n",
       "\n",
       "      seasons  social_drinker       son  distance_from_residence_to_work  \\\n",
       "0   -1.390175        0.872872  0.893723                         0.429556   \n",
       "1   -1.390175        0.872872 -0.017234                        -1.121694   \n",
       "2   -1.390175        0.872872 -0.928191                         1.441240   \n",
       "3   -1.390175        0.872872  0.893723                        -1.661258   \n",
       "4   -1.390175        0.872872  0.893723                         0.429556   \n",
       "..        ...             ...       ...                              ...   \n",
       "735 -1.390175        0.872872  0.893723                         0.429556   \n",
       "736 -1.390175       -1.145644 -0.017234                        -1.256585   \n",
       "737 -1.390175        0.872872 -0.017234                        -1.054248   \n",
       "738 -0.490149        0.872872  0.893723                         0.362110   \n",
       "739  0.409877       -1.145644 -0.017234                         1.036566   \n",
       "\n",
       "     body_mass_index  \n",
       "0           0.775932  \n",
       "1           1.009438  \n",
       "2           1.009438  \n",
       "3          -0.625100  \n",
       "4           0.775932  \n",
       "..               ...  \n",
       "735         0.775932  \n",
       "736         0.542427  \n",
       "737         1.709954  \n",
       "738         1.943459  \n",
       "739        -0.391595  \n",
       "\n",
       "[740 rows x 10 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.iloc[:,[9,7,8,6,1,2,12,11,4,15]]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(32) Create subsets for train and test purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train set and test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(33) Create placeholders for the TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# numFeatures is the number of features in our input data.\n",
    "# In the iris dataset, this number is '4'.\n",
    "numFeatures = X_train.shape[1]\n",
    "\n",
    "# numLabels is the number of classes our data points can be in.\n",
    "# In the iris dataset, this number is '3'.\n",
    "numLabels = Y_train.shape[1]\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "# 'None' means TensorFlow shouldn't expect a fixed number in that dimension\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures]) # Iris has 4 features, so X is a tensor to hold our data.\n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels]) # This will be our correct answers matrix for 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(34) Create random weight and bias for the TensorFlow model that will update automatically during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=0.001,\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=0.001,\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(35) Build the components for the TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(36) Define the cost function and training duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 10000\n",
    "\n",
    "# Defining our learning rate iterations (decay)\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.005,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=X_train.shape[0],\n",
    "                                          decay_rate= 0.95,\n",
    "                                          staircase=True)\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")\n",
    "\n",
    "#Defining our Gradient Descent\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(37) Create a TensorFlow session and initialize the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorflow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize our weights and biases variables.\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "# Initialize all tensorflow variables\n",
    "sess.run(init_OP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(38) Create operations to keep track of the model's efficiency during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax(activation_OP, 1) returns the label with the most probability\n",
    "# argmax(yGold, 1) is the correct label\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "\n",
    "# If every false prediction is 0 and every true prediction is 1, the average returns us the accuracy\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "\n",
    "# Summary op for regression output\n",
    "activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "\n",
    "# Summary op for accuracy\n",
    "accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "\n",
    "# Summary op for cost\n",
    "cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "\n",
    "# Summary ops to check how variables (W, b) are updating after each iteration\n",
    "weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "\n",
    "# Merge all summaries\n",
    "merged = tf.summary.merge([activation_summary_OP, accuracy_summary_OP, cost_summary_OP, weightSummary, biasSummary])\n",
    "\n",
    "# Summary writer\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(39) Train the model and output the final accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 1, cost 301.111, change in cost 301.111\n",
      "step 100, training accuracy 1, cost 221.056, change in cost 80.0549\n",
      "step 200, training accuracy 1, cost 220.308, change in cost 0.748093\n",
      "step 300, training accuracy 1, cost 220.049, change in cost 0.258957\n",
      "step 400, training accuracy 1, cost 219.917, change in cost 0.132233\n",
      "step 500, training accuracy 1, cost 219.837, change in cost 0.0804443\n",
      "step 600, training accuracy 1, cost 219.782, change in cost 0.0542297\n",
      "step 700, training accuracy 1, cost 219.743, change in cost 0.039093\n",
      "step 800, training accuracy 1, cost 219.714, change in cost 0.0294952\n",
      "step 900, training accuracy 1, cost 219.691, change in cost 0.0230865\n",
      "step 1000, training accuracy 1, cost 219.672, change in cost 0.0185394\n",
      "step 1100, training accuracy 1, cost 219.657, change in cost 0.0152283\n",
      "step 1200, training accuracy 1, cost 219.644, change in cost 0.0127716\n",
      "step 1300, training accuracy 1, cost 219.633, change in cost 0.0108185\n",
      "step 1400, training accuracy 1, cost 219.624, change in cost 0.00933838\n",
      "step 1500, training accuracy 1, cost 219.616, change in cost 0.00810242\n",
      "step 1600, training accuracy 1, cost 219.609, change in cost 0.00708008\n",
      "step 1700, training accuracy 1, cost 219.602, change in cost 0.00628662\n",
      "step 1800, training accuracy 1, cost 219.597, change in cost 0.00556946\n",
      "step 1900, training accuracy 1, cost 219.592, change in cost 0.00500488\n",
      "step 2000, training accuracy 1, cost 219.587, change in cost 0.0045166\n",
      "step 2100, training accuracy 1, cost 219.583, change in cost 0.00411987\n",
      "step 2200, training accuracy 1, cost 219.579, change in cost 0.00372314\n",
      "step 2300, training accuracy 1, cost 219.576, change in cost 0.00343323\n",
      "step 2400, training accuracy 1, cost 219.573, change in cost 0.00311279\n",
      "step 2500, training accuracy 1, cost 219.57, change in cost 0.00288391\n",
      "step 2600, training accuracy 1, cost 219.567, change in cost 0.00268555\n",
      "step 2700, training accuracy 1, cost 219.565, change in cost 0.00244141\n",
      "step 2800, training accuracy 1, cost 219.563, change in cost 0.00231934\n",
      "step 2900, training accuracy 1, cost 219.56, change in cost 0.00213623\n",
      "step 3000, training accuracy 1, cost 219.558, change in cost 0.00202942\n",
      "step 3100, training accuracy 1, cost 219.557, change in cost 0.00187683\n",
      "step 3200, training accuracy 1, cost 219.555, change in cost 0.00175476\n",
      "step 3300, training accuracy 1, cost 219.553, change in cost 0.00166321\n",
      "step 3400, training accuracy 1, cost 219.552, change in cost 0.00154114\n",
      "step 3500, training accuracy 1, cost 219.55, change in cost 0.0014801\n",
      "step 3600, training accuracy 1, cost 219.549, change in cost 0.00138855\n",
      "step 3700, training accuracy 1, cost 219.547, change in cost 0.00131226\n",
      "step 3800, training accuracy 1, cost 219.546, change in cost 0.00125122\n",
      "step 3900, training accuracy 1, cost 219.545, change in cost 0.00119019\n",
      "step 4000, training accuracy 1, cost 219.544, change in cost 0.00109863\n",
      "step 4100, training accuracy 1, cost 219.543, change in cost 0.00108337\n",
      "step 4200, training accuracy 1, cost 219.542, change in cost 0.00102234\n",
      "step 4300, training accuracy 1, cost 219.541, change in cost 0.000976562\n",
      "step 4400, training accuracy 1, cost 219.54, change in cost 0.000946045\n",
      "step 4500, training accuracy 1, cost 219.539, change in cost 0.00088501\n",
      "step 4600, training accuracy 1, cost 219.538, change in cost 0.000869751\n",
      "step 4700, training accuracy 1, cost 219.537, change in cost 0.000793457\n",
      "step 4800, training accuracy 1, cost 219.537, change in cost 0.000793457\n",
      "step 4900, training accuracy 1, cost 219.536, change in cost 0.000762939\n",
      "step 5000, training accuracy 1, cost 219.535, change in cost 0.000732422\n",
      "step 5100, training accuracy 1, cost 219.534, change in cost 0.000671387\n",
      "step 5200, training accuracy 1, cost 219.534, change in cost 0.000671387\n",
      "step 5300, training accuracy 1, cost 219.533, change in cost 0.000656128\n",
      "step 5400, training accuracy 1, cost 219.532, change in cost 0.00062561\n",
      "step 5500, training accuracy 1, cost 219.532, change in cost 0.000610352\n",
      "step 5600, training accuracy 1, cost 219.531, change in cost 0.000564575\n",
      "step 5700, training accuracy 1, cost 219.531, change in cost 0.000564575\n",
      "step 5800, training accuracy 1, cost 219.53, change in cost 0.000549316\n",
      "step 5900, training accuracy 1, cost 219.53, change in cost 0.000518799\n",
      "step 6000, training accuracy 1, cost 219.529, change in cost 0.000488281\n",
      "step 6100, training accuracy 1, cost 219.529, change in cost 0.000488281\n",
      "step 6200, training accuracy 1, cost 219.528, change in cost 0.00050354\n",
      "step 6300, training accuracy 1, cost 219.528, change in cost 0.000442505\n",
      "step 6400, training accuracy 1, cost 219.527, change in cost 0.000457764\n",
      "step 6500, training accuracy 1, cost 219.527, change in cost 0.000427246\n",
      "step 6600, training accuracy 1, cost 219.526, change in cost 0.000427246\n",
      "step 6700, training accuracy 1, cost 219.526, change in cost 0.000396729\n",
      "step 6800, training accuracy 1, cost 219.526, change in cost 0.000396729\n",
      "step 6900, training accuracy 1, cost 219.525, change in cost 0.000396729\n",
      "step 7000, training accuracy 1, cost 219.525, change in cost 0.000366211\n",
      "step 7100, training accuracy 1, cost 219.524, change in cost 0.000366211\n",
      "step 7200, training accuracy 1, cost 219.524, change in cost 0.000366211\n",
      "step 7300, training accuracy 1, cost 219.524, change in cost 0.000335693\n",
      "step 7400, training accuracy 1, cost 219.523, change in cost 0.000366211\n",
      "step 7500, training accuracy 1, cost 219.523, change in cost 0.000305176\n",
      "step 7600, training accuracy 1, cost 219.523, change in cost 0.000335693\n",
      "step 7700, training accuracy 1, cost 219.522, change in cost 0.000274658\n",
      "step 7800, training accuracy 1, cost 219.522, change in cost 0.000335693\n",
      "step 7900, training accuracy 1, cost 219.522, change in cost 0.000274658\n",
      "step 8000, training accuracy 1, cost 219.522, change in cost 0.000305176\n",
      "step 8100, training accuracy 1, cost 219.521, change in cost 0.000305176\n",
      "step 8200, training accuracy 1, cost 219.521, change in cost 0.000259399\n",
      "step 8300, training accuracy 1, cost 219.521, change in cost 0.000259399\n",
      "step 8400, training accuracy 1, cost 219.52, change in cost 0.000259399\n",
      "step 8500, training accuracy 1, cost 219.52, change in cost 0.000274658\n",
      "step 8600, training accuracy 1, cost 219.52, change in cost 0.000274658\n",
      "step 8700, training accuracy 1, cost 219.52, change in cost 0.000259399\n",
      "step 8800, training accuracy 1, cost 219.519, change in cost 0.000213623\n",
      "step 8900, training accuracy 1, cost 219.519, change in cost 0.000244141\n",
      "step 9000, training accuracy 1, cost 219.519, change in cost 0.000213623\n",
      "step 9100, training accuracy 1, cost 219.519, change in cost 0.000244141\n",
      "step 9200, training accuracy 1, cost 219.519, change in cost 0.000228882\n",
      "step 9300, training accuracy 1, cost 219.518, change in cost 0.000228882\n",
      "step 9400, training accuracy 1, cost 219.518, change in cost 0.000198364\n",
      "step 9500, training accuracy 1, cost 219.518, change in cost 0.000228882\n",
      "step 9600, training accuracy 1, cost 219.518, change in cost 0.000198364\n",
      "step 9700, training accuracy 1, cost 219.517, change in cost 0.000213623\n",
      "step 9800, training accuracy 1, cost 219.517, change in cost 0.000198364\n",
      "step 9900, training accuracy 1, cost 219.517, change in cost 0.000198364\n",
      "final accuracy on test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize reporting variables\n",
    "cost = 0\n",
    "diff = 1\n",
    "epoch_values = []\n",
    "accuracy_values = []\n",
    "cost_values = []\n",
    "\n",
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "        break\n",
    "    else:\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={X: X_train, yGold: Y_train})\n",
    "        # Report occasional stats\n",
    "        if i % 100 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            train_accuracy, newCost = sess.run([accuracy_OP, cost_OP], feed_dict={X: X_train, yGold: Y_train})\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g, cost %g, change in cost %g\"%(i, train_accuracy, newCost, diff))\n",
    "\n",
    "\n",
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={X: X_test, \n",
    "                                                                yGold: Y_test})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that by \"step 99000\" (that is after 10000 epochs), the change in loss begins to stablize. With the parameters defined as above, the model would reach a peak accuracy of 100% at the end of the training, a quite commendable result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(40) Visualize how the loss behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([np.mean(cost_values[i-50:i]) for i in range(len(cost_values))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(41) Output the predicted result to mannually verify that the model did achieve a 100% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"sess.run\" compares the predicted label with the actual label and outputs True for correct predictions and False for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct=True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Correct=True\n",
       "0            True\n",
       "1            True\n",
       "2            True\n",
       "3            True\n",
       "4            True\n",
       "..            ...\n",
       "217          True\n",
       "218          True\n",
       "219          True\n",
       "220          True\n",
       "221          True\n",
       "\n",
       "[222 rows x 1 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=sess.run(correct_predictions_OP,feed_dict={X:X_test,yGold:Y_test})\n",
    "pred=pd.DataFrame(data=array, columns=[\"Correct=True\"])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double-check if there is any row that the \"sess.run\" does not output True. For a 100% accuracy, we would expect that such conditional selection would output nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct=True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Correct=True]\n",
       "Index: []"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[pred[\"Correct=True\"] != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional selection yields no output. That means the model really correctly predicted all the labels in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
