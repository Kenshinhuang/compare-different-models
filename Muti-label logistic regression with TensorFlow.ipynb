{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center> <font size = \"5\"> Multi-class logistic regression with TensorFlow </font> <center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"Red_wine_quality.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect outliers. Outliers will have label \"-1\" while non-outliers will have label \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:213: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:223: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:417: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      outlier_label\n",
       "0                 1\n",
       "1                 1\n",
       "2                 1\n",
       "3                 1\n",
       "4                 1\n",
       "...             ...\n",
       "1594              1\n",
       "1595              1\n",
       "1596              1\n",
       "1597              1\n",
       "1598              1\n",
       "\n",
       "[1599 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(random_state=0).fit(df)\n",
    "outlier_label=pd.DataFrame(clf.predict(df))\n",
    "outlier_label=outlier_label.rename(columns={0:\"outlier_label\"})\n",
    "outlier_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the otulier labels to the dataset and remove the outlier rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1439 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,outlier_label], axis=1, sort=False)\n",
    "df=df.loc[df[\"outlier_label\"] == 1]\n",
    "df=df.drop([\"outlier_label\"],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset has 1599 rows. The dataset with the outlier removed has 1439 rows. So, IsolationForest detected and removed 160 outliers from the predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the feature importance score for reach predictor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, seperate the predictor variables and target variables. The target variable is the \"quality\" column. All other columns are predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1439, 11)\n",
      "(1439, 1)\n"
     ]
    }
   ],
   "source": [
    "# Seperate the predictor variables and target variables.\n",
    "X=df.drop([\"quality\"],axis=1)\n",
    "y=df[[\"quality\"]]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique classes there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8]\n",
      "There are  6  unique classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "length=len(np.unique(y))\n",
    "print(np.unique(y))\n",
    "print(\"There are \",length,\" unique classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the feature importance score for each predictor variable and sort them in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.672070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.832117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.024580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.767481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.407470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.318385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.853718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35.145856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42.880299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.619682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101.707414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        scores\n",
       "3     1.672070\n",
       "4     3.832117\n",
       "8     4.024580\n",
       "5     5.767481\n",
       "0     7.407470\n",
       "7    11.318385\n",
       "2    20.853718\n",
       "6    35.145856\n",
       "9    42.880299\n",
       "1    49.619682\n",
       "10  101.707414"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the libraries.\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# feature extraction. We are going to output the selection scores for all features and select the features with the highest scores.\n",
    "test = SelectKBest(score_func=f_classif, k=11)\n",
    "fit = test.fit(X, y)\n",
    "features = fit.transform(X)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "# Sort the feature scores in ascending order.\n",
    "scores=fit.scores_\n",
    "scores=pd.DataFrame(scores)\n",
    "scores=scores.rename(columns={0:\"scores\"})\n",
    "scores.sort_values(by=[\"scores\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature has column index 6. That is \"total_sulfur_dioxide\". The least important feature has column index 7. That is density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to select the 8 most important features. To do so, I am going to count 8 features, starting from the bottom of the list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>7.8</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.65</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>11.2</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.58</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>6.2</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.76</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>5.9</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.75</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>6.3</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.71</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>5.9</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.66</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  volatile_acidity  sulphates  total_sulfur_dioxide  citric_acid  \\\n",
       "0         9.4             0.700       0.56                  34.0         0.00   \n",
       "1         9.8             0.880       0.68                  67.0         0.00   \n",
       "2         9.8             0.760       0.65                  54.0         0.04   \n",
       "3         9.8             0.280       0.58                  60.0         0.56   \n",
       "4         9.4             0.700       0.56                  34.0         0.00   \n",
       "...       ...               ...        ...                   ...          ...   \n",
       "1594     10.5             0.600       0.58                  44.0         0.08   \n",
       "1595     11.2             0.550       0.76                  51.0         0.10   \n",
       "1596     11.0             0.510       0.75                  40.0         0.13   \n",
       "1597     10.2             0.645       0.71                  44.0         0.12   \n",
       "1598     11.0             0.310       0.66                  42.0         0.47   \n",
       "\n",
       "      density  fixed_acidity  free_sulfur_dioxide  \n",
       "0     0.99780            7.4                 11.0  \n",
       "1     0.99680            7.8                 25.0  \n",
       "2     0.99700            7.8                 15.0  \n",
       "3     0.99800           11.2                 17.0  \n",
       "4     0.99780            7.4                 11.0  \n",
       "...       ...            ...                  ...  \n",
       "1594  0.99490            6.2                 32.0  \n",
       "1595  0.99512            5.9                 39.0  \n",
       "1596  0.99574            6.3                 29.0  \n",
       "1597  0.99547            5.9                 32.0  \n",
       "1598  0.99549            6.0                 18.0  \n",
       "\n",
       "[1439 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.iloc[:, [10,1,9,6,2,7,0,5]]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.992633</td>\n",
       "      <td>1.029101</td>\n",
       "      <td>-0.612141</td>\n",
       "      <td>-0.336082</td>\n",
       "      <td>-1.405793</td>\n",
       "      <td>0.673407</td>\n",
       "      <td>-0.548791</td>\n",
       "      <td>-0.451312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.586054</td>\n",
       "      <td>2.090154</td>\n",
       "      <td>0.277403</td>\n",
       "      <td>0.776855</td>\n",
       "      <td>-1.405793</td>\n",
       "      <td>0.059232</td>\n",
       "      <td>-0.292828</td>\n",
       "      <td>1.024563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.586054</td>\n",
       "      <td>1.382785</td>\n",
       "      <td>0.055017</td>\n",
       "      <td>0.338425</td>\n",
       "      <td>-1.188809</td>\n",
       "      <td>0.182067</td>\n",
       "      <td>-0.292828</td>\n",
       "      <td>-0.029633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.586054</td>\n",
       "      <td>-1.446689</td>\n",
       "      <td>-0.463884</td>\n",
       "      <td>0.540777</td>\n",
       "      <td>1.631974</td>\n",
       "      <td>0.796243</td>\n",
       "      <td>1.882859</td>\n",
       "      <td>0.181206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.992633</td>\n",
       "      <td>1.029101</td>\n",
       "      <td>-0.612141</td>\n",
       "      <td>-0.336082</td>\n",
       "      <td>-1.405793</td>\n",
       "      <td>0.673407</td>\n",
       "      <td>-0.548791</td>\n",
       "      <td>-0.451312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0.125461</td>\n",
       "      <td>0.439627</td>\n",
       "      <td>-0.463884</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>-0.971826</td>\n",
       "      <td>-1.107701</td>\n",
       "      <td>-1.316681</td>\n",
       "      <td>1.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0.836976</td>\n",
       "      <td>0.144890</td>\n",
       "      <td>0.870433</td>\n",
       "      <td>0.237249</td>\n",
       "      <td>-0.863334</td>\n",
       "      <td>-0.972582</td>\n",
       "      <td>-1.508653</td>\n",
       "      <td>2.500438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.633686</td>\n",
       "      <td>-0.090899</td>\n",
       "      <td>0.796304</td>\n",
       "      <td>-0.133730</td>\n",
       "      <td>-0.700597</td>\n",
       "      <td>-0.591793</td>\n",
       "      <td>-1.252690</td>\n",
       "      <td>1.446241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>-0.179474</td>\n",
       "      <td>0.704890</td>\n",
       "      <td>0.499789</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>-0.754843</td>\n",
       "      <td>-0.757621</td>\n",
       "      <td>-1.508653</td>\n",
       "      <td>1.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0.633686</td>\n",
       "      <td>-1.269847</td>\n",
       "      <td>0.129146</td>\n",
       "      <td>-0.066279</td>\n",
       "      <td>1.143761</td>\n",
       "      <td>-0.745337</td>\n",
       "      <td>-1.444662</td>\n",
       "      <td>0.286626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alcohol  volatile_acidity  sulphates  total_sulfur_dioxide  \\\n",
       "0    -0.992633          1.029101  -0.612141             -0.336082   \n",
       "1    -0.586054          2.090154   0.277403              0.776855   \n",
       "2    -0.586054          1.382785   0.055017              0.338425   \n",
       "3    -0.586054         -1.446689  -0.463884              0.540777   \n",
       "4    -0.992633          1.029101  -0.612141             -0.336082   \n",
       "...        ...               ...        ...                   ...   \n",
       "1434  0.125461          0.439627  -0.463884              0.001172   \n",
       "1435  0.836976          0.144890   0.870433              0.237249   \n",
       "1436  0.633686         -0.090899   0.796304             -0.133730   \n",
       "1437 -0.179474          0.704890   0.499789              0.001172   \n",
       "1438  0.633686         -1.269847   0.129146             -0.066279   \n",
       "\n",
       "      citric_acid   density  fixed_acidity  free_sulfur_dioxide  \n",
       "0       -1.405793  0.673407      -0.548791            -0.451312  \n",
       "1       -1.405793  0.059232      -0.292828             1.024563  \n",
       "2       -1.188809  0.182067      -0.292828            -0.029633  \n",
       "3        1.631974  0.796243       1.882859             0.181206  \n",
       "4       -1.405793  0.673407      -0.548791            -0.451312  \n",
       "...           ...       ...            ...                  ...  \n",
       "1434    -0.971826 -1.107701      -1.316681             1.762500  \n",
       "1435    -0.863334 -0.972582      -1.508653             2.500438  \n",
       "1436    -0.700597 -0.591793      -1.252690             1.446241  \n",
       "1437    -0.754843 -0.757621      -1.508653             1.762500  \n",
       "1438     1.143761 -0.745337      -1.444662             0.286626  \n",
       "\n",
       "[1439 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardized the new dataset that has the outliers removed and contain only the 8 most important features.\n",
    "from sklearn import preprocessing\n",
    "names=X.columns\n",
    "scaler=preprocessing.StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X=pd.DataFrame(X, columns=names)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train set and test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Multi-class logistic regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numFeatures is the number of features in our input data.\n",
    "\n",
    "numFeatures = X_train.shape[1]\n",
    "\n",
    "# numLabels is the number of classes our data points can be in.\n",
    "\n",
    "numLabels = y_train.shape[1]\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "# 'None' means TensorFlow shouldn't expect a fixed number in that dimension\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures]) \n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set weights and biases for the model.We initialize both W and b as tensors full of zeros. Since we are going to learn W and b, their initial value does not matter too much. These variables are the objects which define the structure of our regression model, and we can save them after they have been trained so we can reuse them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly sample from a normal distribution with standard deviation .01\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=0.01,\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=0.01,\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the multi-class logistic regression model with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the components first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-component breakdown of the Logistic Regression equation.\n",
    "# Note that these feed into each other.\n",
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost function and how long the model will be trained for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs in our training\n",
    "numEpochs = 1000\n",
    "\n",
    "# Defining our learning rate iterations (decay)\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0008,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=X_train.shape[0],\n",
    "                                          decay_rate= 0.95,\n",
    "                                          staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining our cost function - Squared Mean Error\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")\n",
    "\n",
    "#Defining our Gradient Descent\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to initialize our weights and biases with zeros or random values via the inbuilt Initialization Op, tf.initialize_all_variables(). This Initialization Op will become a node in our computational graph, and when we put the graph into a session, then the Op will run and create the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorflow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize our weights and biases variables.\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "# Initialize all tensorflow variables\n",
    "sess.run(init_OP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want some additional operations to keep track of our model's efficiency over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax(activation_OP, 1) returns the label with the most probability\n",
    "# argmax(yGold, 1) is the correct label\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "\n",
    "# If every false prediction is 0 and every true prediction is 1, the average returns us the accuracy\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "\n",
    "# Summary op for regression output\n",
    "activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "\n",
    "# Summary op for accuracy\n",
    "accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "\n",
    "# Summary op for cost\n",
    "cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "\n",
    "# Summary ops to check how variables (W, b) are updating after each iteration\n",
    "weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "\n",
    "# Merge all summaries\n",
    "merged = tf.summary.merge([activation_summary_OP, accuracy_summary_OP, cost_summary_OP, weightSummary, biasSummary])\n",
    "\n",
    "# Summary writer\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and run the actual training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 1, cost 11917.2, change in cost 11917.2\n",
      "step 100, training accuracy 1, cost 11917.1, change in cost 0.112305\n",
      "step 200, training accuracy 1, cost 11917, change in cost 0.0966797\n",
      "step 300, training accuracy 1, cost 11917, change in cost 0.078125\n",
      "step 400, training accuracy 1, cost 11916.9, change in cost 0.0693359\n",
      "step 500, training accuracy 1, cost 11916.8, change in cost 0.0585938\n",
      "step 600, training accuracy 1, cost 11916.8, change in cost 0.0527344\n",
      "step 700, training accuracy 1, cost 11916.7, change in cost 0.046875\n",
      "step 800, training accuracy 1, cost 11916.7, change in cost 0.0390625\n",
      "step 900, training accuracy 1, cost 11916.7, change in cost 0.0361328\n",
      "final accuracy on test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize reporting variables\n",
    "cost = 0\n",
    "diff = 1\n",
    "epoch_values = []\n",
    "accuracy_values = []\n",
    "cost_values = []\n",
    "\n",
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "        break\n",
    "    else:\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={X: X_train, yGold: y_train})\n",
    "        # Report occasional stats\n",
    "        if i % 100 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            train_accuracy, newCost = sess.run([accuracy_OP, cost_OP], feed_dict={X: X_train, yGold: y_train})\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g, cost %g, change in cost %g\"%(i, train_accuracy, newCost, diff))\n",
    "\n",
    "\n",
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={X: X_test, \n",
    "                                                                yGold: y_test})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final accuracy on test set is 100%. Very commendable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the accuracy vs cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([np.mean(cost_values[i-60:i]) for i in range(len(cost_values))])\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parameters defined as above, the model has a 100% accuracy on the test data. But let's output the results and see them with our eyes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"sess.run\" compares the predicted label with the actual label and outputs True for correct predictions and False for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct=True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Correct=True\n",
       "0            True\n",
       "1            True\n",
       "2            True\n",
       "3            True\n",
       "4            True\n",
       "..            ...\n",
       "355          True\n",
       "356          True\n",
       "357          True\n",
       "358          True\n",
       "359          True\n",
       "\n",
       "[360 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=sess.run(correct_predictions_OP,feed_dict={X:X_test,yGold:y_test})\n",
    "pred=pd.DataFrame(data=array, columns=[\"Correct=True\"])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double-check if there is any row that the \"sess.run\" does not output True. For a 100% accuracy, we would expect that such conditional selection would output nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct=True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Correct=True]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[pred[\"Correct=True\"] != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional selection yields no output. That means the model really correctly predicted all the labels in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
